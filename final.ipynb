{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Series Completed for Each Patient\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import shap\n",
    "import time\n",
    "import os\n",
    "import wfdb\n",
    "from pathlib import Path\n",
    "import re \n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "class Patient:\n",
    "    def __init__(self):\n",
    "        self.studies = []\n",
    "        self.hAbp = []\n",
    "        self.hIcp = []\n",
    "        self.hct = []\n",
    "    def __str__(self) -> str:\n",
    "        return f\"studies : {len(self.studies)} \"\n",
    "    \n",
    "\n",
    "folder_path = Path('physionet.org/files/neurocritical-pediatric/1.0.0/waves')\n",
    "header = [('ABP', float), ('CBFV', float), ('ICP', float)]\n",
    "\n",
    "patient_static_map = defaultdict(Patient)\n",
    "\n",
    "def process_time_series(folder_path, header):\n",
    "    for filename in folder_path.glob('*.dat'):  # Ensure we process only .dat files\n",
    "        \n",
    "        entity = filename.stem.split(\"_\")\n",
    "        id = entity[0][7:]        \n",
    "        # Read the data record\n",
    "        record = wfdb.rdrecord(str(filename.with_suffix('')), sampfrom=0)\n",
    "        data = np.empty(record.sig_len, dtype=header)\n",
    "        temp_labels = []\n",
    "        \n",
    "        for i, signal in enumerate(record.p_signal.T):\n",
    "            if i == 0:\n",
    "                data['ABP'] = signal\n",
    "            elif i == 1:\n",
    "                data['ICP'] = signal\n",
    "            else:\n",
    "                data['CBFV'] = signal\n",
    "\n",
    "        # normalized = normalize_data(data)\n",
    "        patient_static_map[id].studies.append(data)\n",
    "\n",
    "    print(\"Time Series Completed for Each Patient\")\n",
    "\n",
    "\n",
    "def patient_characteristics():\n",
    "    for filename in folder_path.glob('*.hea'):\n",
    "        entity = filename.stem.split(\"_\")\n",
    "        id = entity[0][7:]\n",
    "\n",
    "        hAbp, hIcp, hct = 0, 0, 0 # Default values        \n",
    "        with open(filename.with_suffix('.hea'), 'r') as f:\n",
    "            for line in f:\n",
    "                if \"#\" in line:\n",
    "                    feature, value = re.search(r'\\b(?:hAbp|hIcp|Hct)\\b', line)[0], re.search(r'\\b\\d+(\\.\\d+)?\\b', line)[0]\n",
    "                    if feature == \"hAbp\":\n",
    "                        hAbp = float(value)\n",
    "                    elif feature == 'hIcp':\n",
    "                        hIcp = float(value)\n",
    "                    elif feature == 'Hct':\n",
    "                        hct = float(value)\n",
    "        \n",
    "        patient_static_map[id].hIcp.append(hIcp)\n",
    "        patient_static_map[id].hAbp.append(hAbp)\n",
    "        patient_static_map[id].hct.append(hct)\n",
    "\n",
    "\n",
    "def process_data():\n",
    "    process_time_series(folder_path, header)\n",
    "    patient_characteristics()\n",
    "        \n",
    "process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import random\n",
    "\n",
    "def rolling_window_split_by_60(data):\n",
    "    window_size = 60\n",
    "    num_windows = len(data) // window_size\n",
    "    windows_data = [data[i*window_size : (i+1)*window_size] for i in range(num_windows)]\n",
    "    return windows_data\n",
    "\n",
    "def estimate_icp(abp, cbfv, fs, icp):\n",
    "    # Convert signals to numpy arrays for computation\n",
    "    abp = np.array(abp)\n",
    "    cbfv = np.array(cbfv)\n",
    "    \n",
    "    def equation(params):\n",
    "        R, C = params\n",
    "        q = cbfv / R\n",
    "        dq_dt = np.gradient(q, 1/fs)\n",
    "        return np.mean(abp - R * q - C * dq_dt)  # Example equation\n",
    "    \n",
    "    def objective_function( params, ground_truth):\n",
    "        prediction = equation(params)\n",
    "        return np.mean((prediction - ground_truth)**2)\n",
    "    \n",
    "    initial = [0.85,0.20]\n",
    "    result = minimize(objective_function, initial, args=(icp,), method='BFGS')\n",
    "    return equation(result.x), result.x\n",
    "\n",
    "def estimate_icp_equation(abp, cbfv, fs, R, C):\n",
    "    q = cbfv / R\n",
    "    dq_dt = np.gradient(q, 1/fs)\n",
    "    return np.mean(abp - R * q - C * dq_dt)\n",
    "\n",
    "def rc_data(sample_fraction=0.5):\n",
    "    actuals = []\n",
    "    estimated = []\n",
    "    train_data = []\n",
    "    rc_y = []\n",
    "    for key in patient_static_map.keys():\n",
    "        for i,study in enumerate(patient_static_map[key].studies):\n",
    "            data = study \n",
    "            waves= rolling_window_split_by_60(data)\n",
    "            for wvform in random.sample(waves, k=int(sample_fraction*len(waves))):\n",
    "                actual_icp = np.mean(wvform['ICP'])\n",
    "                estimated_icp, params = estimate_icp(wvform['ABP'], wvform['CBFV'], 125, actual_icp)\n",
    "                actuals.append(actual_icp)\n",
    "                estimated.append(estimated_icp)\n",
    "                train_data.append([np.mean(wvform['ABP']), np.mean(wvform['CBFV'])])\n",
    "                rc_y.append(params)\n",
    "    return train_data, rc_y\n",
    "\n",
    "def estimate_optimizer():\n",
    "    train, y = rc_data()\n",
    "    model = LinearRegression()\n",
    "    multi_output_model = MultiOutputRegressor(model)\n",
    "    multi_output_model.fit(train, y)\n",
    "    return multi_output_model\n",
    "\n",
    "model = estimate_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.46036779888824164\n",
      "Root Mean Squared Error: 0.7519628193793629\n",
      "R-squared: 0.9336355416432183\n",
      "Median Absolute Error: 0.2627453827284949\n",
      "Explained Variance Score: 0.9337437211632618\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "def split_study_blocks_by_beat(data):\n",
    "    new_header = [('Mean ABP', float), ('Mean CBFV', float), ('ICP Estimate', float)]\n",
    "   \n",
    "    beats = []\n",
    "    estimates = []\n",
    "    labels = []\n",
    "    for wvform in rolling_window_split_by_60(data):\n",
    "        mean_abp = np.mean(wvform['ABP'])\n",
    "        mean_cbfv = np.mean(wvform['CBFV'])\n",
    "        mean_icp = np.mean(wvform['ICP'])\n",
    "        params = model.predict([[mean_abp, mean_cbfv]])\n",
    "        estimate = estimate_icp_equation(np.array(wvform['ABP']), np.array(wvform['CBFV']), 125, params[0][0], params[0][1])\n",
    "        data = [mean_abp, mean_cbfv, estimate*0.05]\n",
    "        beats.append(data)\n",
    "        labels.append(mean_icp)\n",
    "        estimates.append(estimate)\n",
    "\n",
    "    # iterations = np.arange(1, 51)  # Iterations from 1 to 10\n",
    "    # # Creating the plot\n",
    "    # plt.figure(figsize=(10, 6))\n",
    "    # plt.plot(iterations, estimates[:50], label='Estimates', marker='o')  # Plot Array 1\n",
    "    # plt.plot(iterations, labels[:50], label='Actual', marker='x')  # Plot Array 2\n",
    "    # plt.title('Comparison of ICP vs Estimated ICP')\n",
    "    # plt.xlabel('Iteration per 60 beats')\n",
    "    # plt.ylabel('ICP')\n",
    "    # plt.legend()\n",
    "    # plt.grid(True)\n",
    "\n",
    "    # Show the plot\n",
    "    # plt.show()\n",
    "    return np.array(beats), np.array(labels)\n",
    "\n",
    "def rolling_split_by_window(data, labels, window):\n",
    "    train_window = int(window * 0.6)\n",
    "    test_window = int(window*0.2)\n",
    "\n",
    "    X = data[:train_window]\n",
    "    y = labels[len(labels) - test_window-1 : ]\n",
    "    X = np.mean(X, axis=0)\n",
    "    y = np.mean(y)\n",
    "    return X,y\n",
    "\n",
    "def get_MSE(actual, predicted):\n",
    "    \"\"\"Calculate the mean squared error between actual and predicted values.\"\"\"\n",
    "    return np.mean((actual - predicted) ** 2)\n",
    "\n",
    "def test_all_studies(key):\n",
    "    studies = patient_static_map[key].studies\n",
    "    \n",
    "    y_tests = []\n",
    "    y_preds = []\n",
    "    for study in studies:\n",
    "        beats, lbl = split_study_blocks_by_beat(study)\n",
    "        window = 20\n",
    "        current = 0\n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "        while current+window < len(beats):\n",
    "            smallX, smallY = rolling_split_by_window(beats[current:current+window], lbl[current:current+window], window)\n",
    "            X.append(smallX)\n",
    "            y.append(smallY)\n",
    "            current += 1\n",
    "\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "        linear_model = LinearRegression()\n",
    "        linear_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = linear_model.predict(X_test)\n",
    "\n",
    "        # Evaluate the model\n",
    "        # mse = get_MSE(y_test, y_pred)\n",
    "        # print(\"Mean Squared Error:\", mse)\n",
    "        # mses.append(mse)\n",
    "        # explainer = shap.Explainer(linear_model, X_train)\n",
    "\n",
    "        # # Compute SHAP values\n",
    "        # shap_values = explainer(X_test)\n",
    "        # # Summary plot\n",
    "        # shap.summary_plot(shap_values, X_test, feature_names=['ABP', 'CPP', 'Estimate ICP'])\n",
    "\n",
    "        # Dependence plot for a specific feature\n",
    "        # shap.dependence_plot(\"Feature 1\", shap_values.values, X_test, feature_names=['ABP', 'CPP', 'Estimate ICP'])\n",
    "\n",
    "        # # Waterfall plot for the first prediction\n",
    "        # shap.waterfall_plot(shap_values[0])\n",
    "        y_tests.append(y_test)\n",
    "        y_preds.append(y_pred)\n",
    "    return np.concatenate(y_tests),np.concatenate(y_preds)\n",
    "\n",
    "def test_all_studies_forest(key):\n",
    "    studies = patient_static_map[key].studies\n",
    "    y_tests = []\n",
    "    y_preds = []\n",
    "\n",
    "    for study in studies:\n",
    "        beats, lbl = split_study_blocks_by_beat(study)\n",
    "        window = 20\n",
    "        current = 0\n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "        while current+window < len(beats):\n",
    "            smallX, smallY = rolling_split_by_window(beats[current:current+window], lbl[current:current+window], window)\n",
    "            X.append(smallX)\n",
    "            y.append(smallY)\n",
    "            current += 1\n",
    "\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "        # Initialize the RandomForestRegressor\n",
    "        forest = RandomForestRegressor(n_estimators=10)  # 100 trees in the forest\n",
    "\n",
    "        # Fit the model\n",
    "        forest.fit(X_train, y_train)\n",
    "\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = forest.predict(X_test)\n",
    "\n",
    "        # Calculate MSE\n",
    "        \n",
    "        y_tests.append(y_test)\n",
    "        y_preds.append(y_pred)\n",
    "    return np.concatenate(y_tests),np.concatenate(y_preds)\n",
    "\n",
    "def test_all_studies_ridge(key):\n",
    "    studies = patient_static_map[key].studies\n",
    "    \n",
    "    y_tests = []\n",
    "    y_preds = []\n",
    "    for study in studies:\n",
    "        beats, lbl = split_study_blocks_by_beat(study)\n",
    "        window = 20\n",
    "        current = 0\n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "        while current+window < len(beats):\n",
    "            smallX, smallY = rolling_split_by_window(beats[current:current+window], lbl[current:current+window], window)\n",
    "            X.append(smallX)\n",
    "            y.append(smallY)\n",
    "            current += 1\n",
    "\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "        linear_model = Ridge()\n",
    "        linear_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = linear_model.predict(X_test)\n",
    "\n",
    "        # Evaluate the model\n",
    "        # mse = get_MSE(y_test, y_pred)\n",
    "        # print(\"Mean Squared Error:\", mse)\n",
    "        # mses.append(mse)\n",
    "        # explainer = shap.Explainer(linear_model, X_train)\n",
    "\n",
    "        # # Compute SHAP values\n",
    "        # shap_values = explainer(X_test)\n",
    "        # # Summary plot\n",
    "        # shap.summary_plot(shap_values, X_test, feature_names=['ABP', 'CPP', 'Estimate ICP'])\n",
    "\n",
    "        # Dependence plot for a specific feature\n",
    "        # shap.dependence_plot(\"Feature 1\", shap_values.values, X_test, feature_names=['ABP', 'CPP', 'Estimate ICP'])\n",
    "\n",
    "        # # Waterfall plot for the first prediction\n",
    "        # shap.waterfall_plot(shap_values[0])\n",
    "        y_tests.append(y_test)\n",
    "        y_preds.append(y_pred)\n",
    "    return np.concatenate(y_tests),np.concatenate(y_preds)\n",
    "def evaluate_performance(y_test,y_pred):\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    print(\"Mean Absolute Error:\", mae)  \n",
    "    rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(\"Root Mean Squared Error:\", rmse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(\"R-squared:\", r2)\n",
    "    median_ae = median_absolute_error(y_test, y_pred)\n",
    "    print(\"Median Absolute Error:\", median_ae)\n",
    "    explained_variance = explained_variance_score(y_test, y_pred)\n",
    "    print(\"Explained Variance Score:\", explained_variance)\n",
    "# print(test_all_studies_forest('01'))\n",
    "y_test,y_pred = test_all_studies_ridge('01')\n",
    "evaluate_performance(y_test,y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p3env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
